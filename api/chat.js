const DEFAULT_MODEL = process.env.HF_MODEL || "TinyLlama/TinyLlama-1.1B-Chat-v1.0";

export default async function handler(req, res) {
  console.log("ğŸ’¡ HF_TOKEN:", process.env.HF_TOKEN ? "âœ… exists" : "âŒ missing");
  console.log("ğŸ§  Model:", DEFAULT_MODEL);

  if (req.method === "GET" && req.query.ping === "1") {
    return res.status(200).json({
      ok: true,
      route: "/api/chat",
      model: DEFAULT_MODEL,
      hfTokenPresent: !!process.env.HF_TOKEN,
    });
  }


  if (req.method !== "POST") {
    return res.status(405).json({ error: "Method not allowed (GET ä»…æ”¯æŒ ?ping=1)" });
  }

  const { message } = req.body || {};
  if (!message) return res.status(400).json({ error: "Missing message" });

  const HF_TOKEN = process.env.HF_TOKEN;
  if (!HF_TOKEN) return res.status(500).json({ error: "HF_TOKEN not found in environment" });

  const endpoint = `https://api-inference.huggingface.co/models/${encodeURIComponent(DEFAULT_MODEL)}`;
  const systemPrompt =
    "ä½ æ˜¯å¤œç©ºAIï¼Œä¸€ä¸ªæ¸©æŸ”ä½“è´´çš„ä¸­æ–‡èŠå¤©ä¼™ä¼´ã€‚è¯·ç”¨ç®€çŸ­ã€å®‰æŠšçš„è¯­æ°”å›å¤ï¼Œè®©ç”¨æˆ·æ„Ÿåˆ°è¢«ç†è§£ã€‚";
  const prompt = `${systemPrompt}\n\nç”¨æˆ·ï¼š${message}\nå¤œç©ºAIï¼š`;

  // ç®€å•é‡è¯•ï¼ˆæ¨¡å‹åŠ è½½/é™æµï¼‰
  async function callOnce() {
    const resp = await fetch(endpoint, {
      method: "POST",
      headers: {
        Authorization: `Bearer ${HF_TOKEN}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        inputs: prompt,
        parameters: {
          max_new_tokens: 180,
          temperature: 0.8,
          top_p: 0.95,
          return_full_text: false,
        },
        // å…³é”®ï¼šç­‰å¾…æ¨¡å‹åŠ è½½ï¼Œé¿å… 503
        options: { wait_for_model: true, use_cache: true },
      }),
    });
    const text = await resp.text();
    return { resp, text };
  }

  try {
    let out = await callOnce();

    // å¯¹å…¸å‹é”™è¯¯åšä¸€æ¬¡é‡è¯•
    if (out.resp.status === 503 || out.resp.status === 429) {
      await new Promise(r => setTimeout(r, 1500));
      out = await callOnce();
    }

    if (!out.resp.ok) {
      return res.status(500).json({
        error: "HF_API_ERROR",
        status: out.resp.status,
        details: out.text, // æŠŠ HF çš„åŸå§‹è¿”å›ä½“ç»™å‰ç«¯ï¼Œä¾¿äºå®šä½
      });
    }

    // å°è¯•è§£æ
    let data;
    try {
      data = JSON.parse(out.text);
    } catch {
      return res.status(500).json({ error: "HF_API_PARSE_ERROR", raw: out.text });
    }

    // å…¼å®¹ä¸åŒè¿”å›å½¢æ€
    let reply = "";
    if (Array.isArray(data) && data[0]?.generated_text) {
      reply = data[0].generated_text.trim();
    } else if (typeof data === "string") {
      reply = data.trim();
    } else if (data?.generated_text) {
      reply = (data.generated_text || "").trim();
    } else {
      reply = JSON.stringify(data);
    }

    if (!reply) reply = "âœ¨ æˆ‘å¬æ‡‚äº†ï¼Œä¹Ÿè®¸ä½ éœ€è¦ä¸€ç‚¹æ—¶é—´æ”¾æ¾ã€‚";
    return res.status(200).json({ reply });
  } catch (err) {
    console.error("SERVER_ERROR:", err);
    return res.status(500).json({ error: "SERVER_ERROR", message: err.message || String(err) });
  }
}

